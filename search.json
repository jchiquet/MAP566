[
  {
    "href": "index.html#course-description",
    "title": "Welcome",
    "section": "Course description",
    "text": "The objective of this course is to show students how statistics is used in practice to answer a specific question, by introducing a series of important model-based approaches.\nThe students will learn to select and use appropriate statistical methodologies and acquire solid and practical skills by working-out examples on real-world data sets from various areas including medicine, genomics, ecology, and others.\nAll analyses will be conducted with the R software, possibly with interfacing to Python. No strong knwoledge neither of R or Python programming is required (only basic scripting).\n\n\n\n\n\n\nImportant remark\n\n\n\nMuch of the material used in this course is due to Marc Lavielle, who was the first to set up the Statistics in Actions course. We only have made some adjustments to it."
  },
  {
    "href": "index.html#schedule-tentative",
    "title": "Welcome",
    "section": "Schedule (tentative)",
    "text": "Teachers : Julien Chiquet (lecture + 1 PC), Geneviève Robin (2 PC)\nCourse Evaluation: 2 individual homework assignements + a final exam/project\nCourse Language: French with all material in English\nNumerus closus: 80 students\n\nStatistical tests (x1)\n\nTwo-populations comparison\nPower analysis\nMultiple Testing\n\nRegression models (x2)\n\nLinear and Non Linear Regression models\nNonlinear regression models\nInference Diagnostic, Model comparison\n\nMixed effects models (x2)\n\nLinear mixed effects models\nNonlinear mixed effects models\nEM algorithm\n\nMixture models and model-based clustering (x2)\n\nGaussian mixture models for data clustering\nStochastic Block Models for graph clustering\n(Variational) EM algorithm\n\nModel-based Dimension Reduction (x2)\n\nMultivariate Gaussian model\nProbabilistic Gaussian PCA\nGeneralized mixed effect models"
  },
  {
    "href": "docs/tests/lectures-multiple.html#introduction-1",
    "title": "Statistical tests",
    "section": "Introduction",
    "text": "The health effects of a Roundup-tolerant genetically modified maize, cultivated with or without Roundup, and Roundup alone, were studied during a 2 years study in rats.\nFor each sex, one control group had access to plain water and standard diet from the closest isogenic non-transgenic maize control; six groups were fed with 11, 22 and 33% of GM NK603 maize either treated or not with Roundup. The final three groups were fed with the control diet and had access to water supplemented with different concentrations of Roundup.\nA sample of 200 rats including 100 males and 100 females was randomized into 20 groups of 10 rats of the same sex. Within each group, rats received the same diet. For each sex, there are therefore nine experimental groups and one control group.\nThe file ratSurvival.csv reports the lifespan (in days) for each animal. Here, the experiment stopped after 720 days. Then, the reported survival time is 720 for those animals who were still alive at the end of the experiment.\nSee the opinion of the Haut Conseil des Biotechnologies for more information about this study.\nHere is a summary of the data,\n\ndata <- read.csv(\"ratSurvival.csv\", stringsAsFactors = T)\nhead(data)\n\n  time regimen gender\n1  490 control   male\n2  575 control   male\n3  590 control   male\n4  605 control   male\n5  610 control   male\n6  635 control   male\n\nsummary(data)\n\n      time              regimen      gender   \n Min.   :100.0   control    :20   female:100  \n 1st Qu.:590.0   NK603-11%  :20   male  :100  \n Median :660.0   NK603-11%+R:20               \n Mean   :631.6   NK603-22%  :20               \n 3rd Qu.:720.0   NK603-22%+R:20               \n Max.   :720.0   NK603-33%  :20               \n                 (Other)    :80               \n\nlevels(data$regimen)\n\n [1] \"control\"     \"NK603-11%\"   \"NK603-11%+R\" \"NK603-22%\"   \"NK603-22%+R\"\n [6] \"NK603-33%\"   \"NK603-33%+R\" \"RoundUp A\"   \"RoundUp B\"   \"RoundUp C\""
  },
  {
    "href": "docs/tests/lectures-multiple.html#single-comparison-between-2-groups",
    "title": "Statistical tests",
    "section": "Single comparison between 2 groups",
    "text": "One objective of this study is the comparison of the survival between the control group and the experimental groups.\nConsider for instance the control group of females\n\ndata.control <- subset(data, regimen==\"control\" & gender==\"female\")\ndata.control$time\n\n [1] 540 645 720 720 720 720 720 720 720 720\n\n\nOnly 2 rats of this group died before the end of the experiment. On the other hand, 7 females of the group fed with 22% of maize NK693 died during the experiment.\n\ndata.test <- subset(data, regimen==\"NK603-22%\" & gender==\"female\")\ndata.test$time\n\n [1] 290 475 480 510 550 555 650 720 720 720\n\n\nA negative effect of the diet on the survival means that the rats of the experimental group tend to die before those of the control group. Then, we would like to test \\begin{aligned}\n& H_0: \\ ``\\text{the NK603 22% diet has no effect on the survival of female rats }\" \\\\\n\\text{versus } & H_1: \\ ``\\text{the NK603 22% diet leads to decreased survival time for female rats}\" \\end{aligned}\nIn terms of survival functions, that means that, under H_1, the probability to be alive at a given time t is lower for a rat of the experimental group than for a rat of the control group. We then would like to test \\begin{aligned}\n& H_0: \\ ``\\prob{T_{\\rm test}>t} = \\prob{T_{\\rm control}>t}, \\text{ for any } t>0\" \\\\\n\\text{versus } & H_1: \\ ``\\prob{T_{\\rm test}>t} < \\prob{T_{\\rm control}>t}, \\text{ for any } t>0\" \n\\end{aligned}\nBecause of the (right) censoring process, we cannot just compare the mean survival times using a t-test. On the other hand, we can use the Wilcoxon-Mann-Whitney test which precisely aims to compare the ranks of the survival times in both groups.\n\nwilcox.test(data.test$time, data.control$time, alternative=\"less\")\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  data.test$time and data.control$time\nW = 22, p-value = 0.01144\nalternative hypothesis: true location shift is less than 0\n\n\nHere, the p-value should lead us to reject the null hypothesis and conclude that 22% of the GM maize in the diet has a negative effect on the survival."
  },
  {
    "href": "docs/tests/lectures-multiple.html#a-single-comparison-among-many-others",
    "title": "Statistical tests",
    "section": "A single comparison… among many others",
    "text": "Should we really accept this conclusion as it stands? No, because we don’t know the whole story… Remember that there are 9 experimental groups for each sex. Then, 18 comparisons with the control groups are performed.\n\nlibrary(ggplot2) ; theme_set(theme_bw())\npval <- stat <- gender <- regimen <- NULL\nfor (g in levels(data$gender)) {\n  data.control <- subset(data, regimen==\"control\" & gender==g)\n  for (r in levels(data$regimen)) {\n    if (r != \"control\") {\n      data.test <- subset(data, gender==g & regimen==r)\n      wt <- wilcox.test(data.test$time, data.control$time, alternative=\"less\")\n      pval <- c(pval,wt$p.value)\n      stat <- c(stat,wt$statistic)\n      gender <- c(gender, g)\n      regimen <- c(regimen, r)\n    }\n  }\n}\nR <- data.frame(gender=gender, regimen=regimen,  stat=stat, p.value=pval)\nR <-  R[order(R$p.value),]\nR\n\n   gender     regimen stat    p.value\n3  female   NK603-22% 22.0 0.01143779\n4  female NK603-22%+R 25.0 0.02131745\n9  female   RoundUp C 26.5 0.02845455\n1  female   NK603-11% 33.0 0.07166095\n8  female   RoundUp B 34.0 0.08459162\n7  female   RoundUp A 34.5 0.09156610\n6  female NK603-33%+R 36.0 0.11556850\n5  female   NK603-33% 39.0 0.17583926\n2  female NK603-11%+R 40.0 0.18797769\n14   male   NK603-33% 40.5 0.24733242\n13   male NK603-22%+R 42.0 0.28493944\n11   male NK603-11%+R 50.0 0.51508635\n15   male NK603-33%+R 51.0 0.54532608\n18   male   RoundUp C 54.5 0.64764235\n17   male   RoundUp B 58.5 0.75283120\n12   male   NK603-22% 64.0 0.86465902\n10   male   NK603-11% 74.5 0.97160483\n16   male   RoundUp A 75.5 0.97688776\n\n\nLet us plot the ordered p-values:\n\nggplot(data=R) + geom_point(aes(x=1:18,color=regimen,y=p.value,shape=gender), size=4) + \n  scale_y_log10() + xlab(\"regimen\") + ylab(\"p-value\") + scale_x_continuous(breaks=NULL)\n\n\n\n\nIf we then decide to only report the largest observed differences, associated to the smallest p-values, how can we conclude that these differences are statistically significant?"
  },
  {
    "href": "docs/tests/lectures-multiple.html#permutation-test",
    "title": "Statistical tests",
    "section": "Permutation test",
    "text": "A permutation test (also called a randomization test) is a type of statistical significance test in which the distribution of the test statistic under the null hypothesis is obtained by calculating all possible values of the test statistic under rearrangements of the labels on the observed data points. If the labels are exchangeable under the null hypothesis, then the resulting tests yield exact significance levels. Prediction intervals can also be derived.\nIn our example, imagine that the null hypothesis is true. We can then randomly exchange the labels (i.e. the regimen) and perform the 18 comparisons between the experimental groups and the control groups.\n\nset.seed(100)\ndperm.m <- subset(data,  gender==\"male\")\nn.m <- dim(dperm.m)[1]\ndperm.m$regimen <- dperm.m$regimen[sample(n.m)]\ndperm.f <- subset(data,  gender==\"female\")\nn.f <- dim(dperm.f)[1]\ndperm.f$regimen <- dperm.f$regimen[sample(n.f)]\ndperm <- rbind(dperm.m,dperm.f)\n\npval <- gender <- regimen <- NULL\nfor (g in levels(dperm$gender)) {\n  dperm.control <- subset(dperm, regimen==\"control\" & gender==g)\n  for (r in levels(dperm$regimen)) {\n    if (r != \"control\") {\n      dperm.test <- subset(dperm, gender==g & regimen==r)\n      wt <- wilcox.test(dperm.test$time, dperm.control$time, alternative=\"less\")\n      pval <- c(pval,wt$p.value)\n      gender <- c(gender, g)\n      regimen <- c(regimen, r)\n    }\n  }\n}\nR.p <- data.frame(gender=gender, regimen=regimen, p.value=pval)\nRo.p <-  R.p[order(R.p$p.value),]\n\nThe test statistics and the p-values now really behave how they are supposed to behave under the null hypothesis\n\nggplot(data=Ro.p) + geom_point(aes(x=1:18,color=regimen,y=p.value,shape=gender), size=4) + \n  scale_y_log10() + xlab(\"regimen\") + ylab(\"p-value\") + scale_x_continuous(breaks=NULL)\n\n\n\n\nIf we now repeat the same experiment using many different permutations, we will be able to estimate the m distributions of the m test statistics as well as the m distributions of the m p-values under the null hypothesis.\n\nL <- 1000\ndperm.m <- subset(data,  gender==\"male\")\nn.m <- dim(dperm.m)[1]\ndperm.f <- subset(data,  gender==\"female\")\nn.f <- dim(dperm.f)[1]\nPV <- ST <- NULL\n\nfor (l in (1:L)) {\n  dperm.m$regimen <- dperm.m$regimen[sample(n.m)]\n  dperm.f$regimen <- dperm.f$regimen[sample(n.f)]\n  dperm <- rbind(dperm.m,dperm.f)\n  pval <- stat <- NULL\n  for (g in levels(dperm$gender)) {\n    dperm.control <- subset(dperm, regimen==\"control\" & gender==g)\n    for (r in levels(dperm$regimen)) {\n      if (r != \"control\") {\n        dperm.test <- subset(dperm, gender==g & regimen==r)\n        wt <- wilcox.test(dperm.test$time, dperm.control$time, alternative=\"less\")\n        pval <- c(pval,wt$p.value)\n        stat <- c(stat,wt$statistic)\n      }\n    }\n  }\n  PV <- rbind(PV,sort(pval))\n  ST <- rbind(ST,sort(stat))\n}\n\nWe can estimate, for instance, prediction intervals of level 90% for the m=18 ordered p-values\n\nq <- apply(PV, MARGIN = 2, quantile, probs = c(0.05, 0.5, 0.95))\nq <- as.data.frame(t(q))\nnames(q) <- c(\"low\",\"median\",\"up\")\nq$rank <- 1:dim(q)[1]\n\nand plot them… ::: {.cell}\npl <- ggplot(data=q) +\n  geom_errorbar(aes(x=rank, ymin=low, ymax=up), width=0.2,size=1.5,colour=\"grey50\") +\n  scale_y_log10() + xlab(\"regimen\") + ylab(\"p-value\") + scale_x_continuous(breaks=NULL) \npl\n\n\n\n::: … with the original p-values\n\npl +  geom_point(data=R, aes(x=1:18,color=regimen,y=p.value,shape=gender), size=4) \n\n\n\n\nHere, all the p-values, including the smallest ones, belong to the 90% prediction intervals: all the observed p-values behave individually how they are expected to behave under the null hypothesis.\nIn particular, when 18 comparisons are performed, it’s not unlikely under the null hypothesis to obtain a smallest p-value less than or equal to the observed one (0.011).\nThe probability of such event can easily be estimated by Monte Carlo simulation. Let p_{(1),\\ell} be the smallest p-value obtained from the \\ell-th replicate of the Monte Carlo. Then,\n \\prob{p_{(1)} \\leq p_{(1)}^{\\rm obs}}  \\simeq  \\frac{1}{L} \\sum_{\\ell=1}^{L} \\one\\left\\{p_{(1),\\ell} \\leq p_{(1)}^{\\rm obs}\\right\\}  ::: {.cell}\nmean(ST[,1]<R$stat[1])\n\n[1] 0.152\n\n:::"
  },
  {
    "href": "docs/tests/lectures-multiple.html#the-bonferroni-correction",
    "title": "Statistical tests",
    "section": "The Bonferroni correction",
    "text": "Imagine that we perform m comparisons and that all the m null hypotheses are true, i.e. m=m_{0\\cdot}.. If we use the same significance level \\alpha_m for the m tests, how should we choose \\alpha_m in order to control the family-wise error rate (FWER)?\n \\begin{aligned}\n{\\rm FWER} &= \\prob{m_{01}\\geq 1} \\\\\n&= 1 - \\prob{m_{01}= 0}  \\\\\n&= 1 - (1-\\alpha_m)^m\n\\end{aligned} \nThen, if we set FWER=\\alpha, the significance level for each individual test should be \\begin{aligned} \n\\alpha_m &=  1 - (1-\\alpha)^{\\frac{1}{m}} \\quad \\quad (\\text{Sidak correction})\\\\\n& \\simeq  \\frac{\\alpha}{m} \\quad \\quad (\\text{Bonferroni correction})\n\\end{aligned}\nLet p_k be the p-value of the k-th test. Using the Bonferroni correction, the k-th test is significant if   p_k \\leq \\alpha_m \\quad  \\Longleftrightarrow \\quad   m \\, p_k \\leq \\alpha  We can then either compare the original p-value p_k to the corrected significance level \\alpha/m, or compare the adjusted p-value p_k^{\\rm (bonferroni)} =\\min(1, m \\, p_k) to the critical value \\alpha.\n\nm <- nrow(R)\nR$pv.bonf <- pmin(1, R$p.value*m)\nR\n\n   gender     regimen stat    p.value   pv.bonf\n3  female   NK603-22% 22.0 0.01143779 0.2058803\n4  female NK603-22%+R 25.0 0.02131745 0.3837141\n9  female   RoundUp C 26.5 0.02845455 0.5121818\n1  female   NK603-11% 33.0 0.07166095 1.0000000\n8  female   RoundUp B 34.0 0.08459162 1.0000000\n7  female   RoundUp A 34.5 0.09156610 1.0000000\n6  female NK603-33%+R 36.0 0.11556850 1.0000000\n5  female   NK603-33% 39.0 0.17583926 1.0000000\n2  female NK603-11%+R 40.0 0.18797769 1.0000000\n14   male   NK603-33% 40.5 0.24733242 1.0000000\n13   male NK603-22%+R 42.0 0.28493944 1.0000000\n11   male NK603-11%+R 50.0 0.51508635 1.0000000\n15   male NK603-33%+R 51.0 0.54532608 1.0000000\n18   male   RoundUp C 54.5 0.64764235 1.0000000\n17   male   RoundUp B 58.5 0.75283120 1.0000000\n12   male   NK603-22% 64.0 0.86465902 1.0000000\n10   male   NK603-11% 74.5 0.97160483 1.0000000\n16   male   RoundUp A 75.5 0.97688776 1.0000000\n\n\nUsing the Bonferroni correction, none of the 18 comparisons is significant.\nRemark: the function p.adjust proposes several adjustements of the p-values for multiple comparisons, including the Bonferroni adjustment:\n\np.adjust(R$p.value, method = \"bonferroni\")\n\n [1] 0.2058803 0.3837141 0.5121818 1.0000000 1.0000000 1.0000000 1.0000000\n [8] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\n[15] 1.0000000 1.0000000 1.0000000 1.0000000\n\n\nThe Bonferroni correction is appropriate when a single false positive in a set of tests would be a problem. It is mainly useful when there are a fairly small number of multiple comparisons and very few of them might be significant. The main drawback of the Bonferroni correction is its lack of power: it may lead to a very high rate of false negatives.\nAssume, for instance that all the female rats of all the experimental groups die before the end of the experiment. Each of the m=18 original tests is significant, but the Bonferroni correction would lead to considering none of these tests as significant:\n\nx <- subset(data, regimen==\"control\" & gender==\"female\")$time\ny <- seq(610,700,length=10)\nc(wilcox.test(x,y,\"greater\")$p.value, wilcox.test(x,y,\"greater\")$p.value*18)\n\n[1] 0.004444026 0.079992464"
  },
  {
    "href": "docs/tests/lectures-multiple.html#detecting-associations",
    "title": "Statistical tests",
    "section": "Detecting associations",
    "text": "(Example from Handbook of Biological Statistics)\nGarc?a-Arenzana et al. (2014) tested associations of 25 dietary variables with mammographic density, an important risk factor for breast cancer, in Spanish women. They found the following results\n\ndata <- read.csv(\"dietary.csv\", stringsAsFactors = T)\ndata\n\n             dietary p.value\n1     Total calories   0.001\n2          Olive oil   0.008\n3         Whole milk   0.039\n4         White meat   0.041\n5           Proteins   0.042\n6               Nuts   0.061\n7  Cereals and pasta   0.074\n8         White fish   0.205\n9             Butter   0.212\n10        Vegetables   0.216\n11      Skimmed milk   0.222\n12          Red meat   0.251\n13             Fruit   0.269\n14              Eggs   0.275\n15         Blue fish   0.340\n16           Legumes   0.341\n17     Carbohydrates   0.384\n18          Potatoes   0.569\n19             Bread   0.594\n20              Fats   0.696\n21            Sweets   0.762\n22    Dairy products   0.940\n23 Semi-skimmed milk   0.942\n24        Total meat   0.975\n25    Processed meat   0.986\n\n\n\nWe can see that five of the variables show a significant p-value (<0.05). However, because Garc?a-Arenzana et al. (2014) tested 25 dietary variables, we would expect one or two variables to show a significant result purely by chance, even if diet had no real effect on mammographic density.\nApplying the Bonferroni correction, we divide \\alpha=0.05 by the number of tests (m=25) to get the Bonferroni critical value, so a test would have to have p<0.002 to be significant. Under that criterion, only the test for total calories is significant.\nAn alternative approach is to control the false discovery rate, i.e the expected proportion of ``discoveries” (significant results) that are actually false positives. FDR control offers a way to increase power while maintaining some principled bound on error.\nImagine for instance that we compare expression levels for 20,000 genes between liver tumors and normal liver cells. We are going to do additional experiments on any genes that show a significant difference between the normal and tumor cells. Then, because we don’t want to miss genes of interest, we are willing to accept up to 25% of the genes with significant results being false positives. We’ll find out they’re false positives when we do the followup experiments. In this case, we would set the false discovery rate to 25%."
  },
  {
    "href": "docs/tests/lectures-multiple.html#the-benjamini-hochberg-procedure",
    "title": "Statistical tests",
    "section": "The Benjamini-Hochberg procedure",
    "text": "The Benjamini-Hochberg (BH) procedure controls the FDR… and it is simple to use!\nIndeed, for a given \\alpha and a given sequence of ordered p-values P_{(1)}, P_{(2)}, , P_{(m)}, it consists in computing the m adjusted p-values defined as\n P_{(i)}^{\\rm BH} = \\min\\left( P_{(i)}\\frac{m}{i} \\ , \\ P_{(i+1)}^{\\rm BH} \\right)\n\np.bh <- data$p.value\nm <- length(p.bh)\nfor (i in ((m-1):1)) \n  p.bh[i] <- min(data$p.value[i]*m/i , p.bh[i+1])\ndata$p.bh <- p.bh\ndata\n\n             dietary p.value      p.bh\n1     Total calories   0.001 0.0250000\n2          Olive oil   0.008 0.1000000\n3         Whole milk   0.039 0.2100000\n4         White meat   0.041 0.2100000\n5           Proteins   0.042 0.2100000\n6               Nuts   0.061 0.2541667\n7  Cereals and pasta   0.074 0.2642857\n8         White fish   0.205 0.4910714\n9             Butter   0.212 0.4910714\n10        Vegetables   0.216 0.4910714\n11      Skimmed milk   0.222 0.4910714\n12          Red meat   0.251 0.4910714\n13             Fruit   0.269 0.4910714\n14              Eggs   0.275 0.4910714\n15         Blue fish   0.340 0.5328125\n16           Legumes   0.341 0.5328125\n17     Carbohydrates   0.384 0.5647059\n18          Potatoes   0.569 0.7815789\n19             Bread   0.594 0.7815789\n20              Fats   0.696 0.8700000\n21            Sweets   0.762 0.9071429\n22    Dairy products   0.940 0.9860000\n23 Semi-skimmed milk   0.942 0.9860000\n24        Total meat   0.975 0.9860000\n25    Processed meat   0.986 0.9860000\n\n\nNotice that we could equivalently use the function p.adjust: ::: {.cell}\np.adjust(data$p.value, method = \"BH\")\n\n [1] 0.0250000 0.1000000 0.2100000 0.2100000 0.2100000 0.2541667 0.2642857\n [8] 0.4910714 0.4910714 0.4910714 0.4910714 0.4910714 0.4910714 0.4910714\n[15] 0.5328125 0.5328125 0.5647059 0.7815789 0.7815789 0.8700000 0.9071429\n[22] 0.9860000 0.9860000 0.9860000 0.9860000\n\n:::\nThen, the discoveries, i.e. the significant tests, are those with an ajusted p-value less than \\alpha.\nIt can be shown that this procedure guarantees that for independent tests, and for any alternative hypothesis,\n\\begin{aligned}\n{\\rm FDR} &= \\esp{\\frac{m_{01}}{m_{01} + m_{11}}} \\\\\n&\\leq \\frac{m_{0\\cdot}}{m} \\alpha \\\\\n&\\leq \\alpha \n\\end{aligned} where m_{0\\cdot} is the (unknown) total number of true null hypotheses, and where the first inequality is an equality with continuous p-value distributions.\nIn our example, the first five tests would be significant with \\alpha=0.25, which means that we expect no more than 25% of these 5 tests to be false discoveries.\nRemark 1: The BH procedure is equivalent to consider as significant the non adjusted p-values smaller than a threshold P_{\\rm BH} defined as\n P_{\\rm BH} = \\max_i \\left\\{ P_{(i)}: \\ \\ P_{(i)} \\leq \\alpha \\frac{i}{m}  \\right\\}  In other words, the largest p-value that has P_{(i)}<(i/m)\\alpha is significant, and all of the P-values smaller than it are also significant, even the ones that aren’t less than their Benjamini-Hochberg critical value \\alpha \\times i/m\n\nalpha <- 0.25\nm <- dim(data)[1]\ndata$critical.value <- (1:m)/m*alpha\ndata\n\n             dietary p.value      p.bh critical.value\n1     Total calories   0.001 0.0250000           0.01\n2          Olive oil   0.008 0.1000000           0.02\n3         Whole milk   0.039 0.2100000           0.03\n4         White meat   0.041 0.2100000           0.04\n5           Proteins   0.042 0.2100000           0.05\n6               Nuts   0.061 0.2541667           0.06\n7  Cereals and pasta   0.074 0.2642857           0.07\n8         White fish   0.205 0.4910714           0.08\n9             Butter   0.212 0.4910714           0.09\n10        Vegetables   0.216 0.4910714           0.10\n11      Skimmed milk   0.222 0.4910714           0.11\n12          Red meat   0.251 0.4910714           0.12\n13             Fruit   0.269 0.4910714           0.13\n14              Eggs   0.275 0.4910714           0.14\n15         Blue fish   0.340 0.5328125           0.15\n16           Legumes   0.341 0.5328125           0.16\n17     Carbohydrates   0.384 0.5647059           0.17\n18          Potatoes   0.569 0.7815789           0.18\n19             Bread   0.594 0.7815789           0.19\n20              Fats   0.696 0.8700000           0.20\n21            Sweets   0.762 0.9071429           0.21\n22    Dairy products   0.940 0.9860000           0.22\n23 Semi-skimmed milk   0.942 0.9860000           0.23\n24        Total meat   0.975 0.9860000           0.24\n25    Processed meat   0.986 0.9860000           0.25\n\n\n\nlibrary(gridExtra)\npl1 <- ggplot(data) + geom_line(aes(x=1:m,y=p.value), colour=\"blue\") +\ngeom_line(aes(x=1:m,y=critical.value), colour=\"red\") +xlab(\"(i)\")\ngrid.arrange(pl1,pl1 + xlim(c(1,8)) + ylim(c(0,0.21)) + geom_vline(xintercept=5.5))\n\n\n\n\nThe largest p-value with P_{(i)}<(i/m)\\alpha is proteins, where the individual p-value (0.042) is less than the (i/m)\\alpha value of 0.050. Thus the first five tests would be significant.\nRemark 2: The FDR is not bounded by \\alpha, but by (m_{0\\cdot}/m) \\alpha. We could increase the global power of the tests and get a FDR equal to the desired level \\alpha, either by defining the critical values as (i/m_{0\\cdot})\\alpha, or by multiplying the adjusted p-values by m_{0\\cdot}/m.\nUnfortunately, m_{0\\cdot} is unknown… but it can be estimated, as the number of non significant tests for instance.\n\nm0.est <- sum(data$p.bh>alpha)\ndata$crit.valc <- round(data$critical.value*m/m0.est,4)\ndata$p.bhc <- round(data$p.bh*m0.est/m,4)\nhead(data,10)\n\n             dietary p.value      p.bh critical.value crit.valc  p.bhc\n1     Total calories   0.001 0.0250000           0.01    0.0125 0.0200\n2          Olive oil   0.008 0.1000000           0.02    0.0250 0.0800\n3         Whole milk   0.039 0.2100000           0.03    0.0375 0.1680\n4         White meat   0.041 0.2100000           0.04    0.0500 0.1680\n5           Proteins   0.042 0.2100000           0.05    0.0625 0.1680\n6               Nuts   0.061 0.2541667           0.06    0.0750 0.2033\n7  Cereals and pasta   0.074 0.2642857           0.07    0.0875 0.2114\n8         White fish   0.205 0.4910714           0.08    0.1000 0.3929\n9             Butter   0.212 0.4910714           0.09    0.1125 0.3929\n10        Vegetables   0.216 0.4910714           0.10    0.1250 0.3929\n\n\nWe would consider the 7 first p-values as significant using this new correction."
  },
  {
    "href": "docs/tests/lectures-multiple.html#a-monte-carlo-simulation",
    "title": "Statistical tests",
    "section": "A Monte Carlo simulation",
    "text": "Let us perform a Monte Carlo simulation to better understand the impact of these corrections.\nLet us assume that we observe (x_{ij}, 1\\leq i \\leq n_x, 1 \\leq j \\leq m) and (y_{ij}, 1\\leq i \\leq n_y, 1 \\leq j \\leq m) where ,\n\\begin{aligned}\nx_{ij} & \\iid {\\cal N}(\\mu_{x,j} \\ , \\ \\sigma_x^2) \\\\\ny_{ij} & \\iid {\\cal N}(\\mu_{y,j} \\ , \\ \\sigma_y^2) \n\\end{aligned} \nFor j=1,2,\\ldots, m, we want to test H_{0,j}: \\mu_{x,j}=\\mu_{y,j} versus H_{1,j}: \\mu_{x,j} \\neq \\mu_{y,j}.\nFor the simulation, we will use m=140, n_x=n_y=50, \\sigma_x^2=\\sigma_y^2=1 and \\mu_{x,j}=0 for 1\\leq j \\leq m.\nFurthermore, the null hypothesis is true for the first m_{0,\\cdot}=120 variables, assuming that \\mu_{y,j}=0 for 1\\leq j \\leq m_{0,\\cdot}. Then, for m_{0,\\cdot}+1\\leq j \\leq m, \\mu_{y,j} varies from 0.3 to 0.6, which means that the alternative hypothesis is true for these m_{1,\\cdot}=20 variables.\n\nnx <- 50\nny <- 50\nm0 <- 120\nm1 <- 20\nmu.x <- rep(0, m0+m1)\nmu.y <- c(rep(0,m0),seq(0.3,0.6,length=m1))\n\nFor each of the L=1000 simulated replicate of the same experiment, we will randomly sample observation x and y from the model and perform a t-test for each of the m=140 variables. We therefore get m=140 p-values for each of these L=1000 replicates.\n\nL <- 1000\nm <- m0+m1\nset.seed(1234)\npval <- matrix(ncol=L,nrow=m)\nfor (l in (1:L)) {\n  x.sim <- matrix(rnorm(nx*m, mu.x), ncol=nx)\n  y.sim <- matrix(rnorm(ny*m, mu.y), ncol=ny)\n  dat <- cbind(x.sim, y.sim)\n  pval[,l] <- apply(dat, 1, function(dat) {\n    t.test(x = dat[1:nx], y = dat[(nx + 1):(nx + ny)])$p.value})\n}\n\nSetting the significance level \\alpha to 0.2, we can compute for each replicate the numbers of true and false discoveries m_{11} and m_{01}, as well as the numbers of true and false nondiscoveries m_{00} and m_{10}.\nWe can then compute the proportion of wrongly rejected null hypotheses\n\nalpha=0.2\nm01 <- colSums(pval[1:m0,] < alpha)\nmean(m01/m0)\n\n[1] 0.2002\n\n\nAs expected, this proportion is close to \\alpha which is precisely the probability to wrongly reject the null hypothesis.\nThe proportion of correctly rejected null hypotheses is an estimate of the power of the test\n\nm11 <- colSums(pval[(m0+1):m,] < alpha)\nmean(m11/m1)\n\n[1] 0.8091\n\n\nThe False Discovery Rate is estimated as the proportion of false discoveries\n\nmean(m01/(m01+m11))\n\n[1] 0.5934879\n\n\nThis means that among the significant results, about 60% of them are false discoveries.\nLet us now apply the Bonferroni correction, and compute the proportion of wrongly and correctly rejected null hypotheses and the proportion of false discoveries\n\npval.b <- apply(pval,2, function(pval) {p.adjust(pval,method=\"bonferroni\")})\nm01.b <- colSums(pval.b[1:m0,] < alpha)\nm11.b <- colSums(pval.b[(m0+1):m,] < alpha)\nc(mean(m01.b/m0), mean(m11.b/m1),mean(m01.b/(m01.b+m11.b),na.rm=TRUE))\n\n[1] 0.001533333 0.184050000 0.043928612\n\n\nVery few of the true null hypotheses are rejected, which may be a good point, but the price to pay is a very low power (less that 20%).\nThe familywise error rate (FWER) is the probability \\prob{m_{01}\\geq 1} to reject at least one of the true null hypothesis. This probability remains quite small when the Bonferroni correction is used.\n\nmean(m01.b>=1)\n\n[1] 0.165\n\n\nThe Benjamini-Hochberg correction increases the power and controls the FDR as expected since the proportion of false discoveries remains below the level \\alpha.\n\npval.bh <- apply(pval,2, function(pval) {p.adjust(pval,method=\"BH\")})\nm01.bh <- colSums(pval.bh[1:m0,] < alpha)\nm11.bh <- colSums(pval.bh[(m0+1):m,] < alpha)\nc(mean(m01.bh/m0), mean(m11.bh/m1),mean(m01.bh/(m01.bh+m11.bh),na.rm=TRUE))\n\n[1] 0.01814167 0.42890000 0.17477153\n\n\nLastly, we can slightly improve the BH procedure by multiplying the p-values by the ratio \\hat{m}_{0\\cdot}/m\n\npval.bhc <- pval.bh\nfor (l in (1:L)) {\n  m0e <- sum(pval.bh[,l]>alpha)\n  pval.bhc[,l] <- pval.bh[,l]*m0e/m\n}\n\nm01.bhc <- colSums(pval.bhc[1:m0,] < alpha)\nm11.bhc <- colSums(pval.bhc[(m0+1):m,] < alpha)\nc(mean(m01.bhc/m0), mean(m11.bhc/m1),mean(m01.bhc/(m01.bhc+m11.bhc),na.rm=TRUE))\n\n[1] 0.02073333 0.44520000 0.18629044\n\n\n\nBenjamini, Y., and Y. Hochberg. 1995. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society B 57: 289-300.\n\n\nGarcia-Arenzana, N., E.M. Navarrete-Munoz, V. Lope, P. Moreo, S. Laso-Pablos, N. Ascunce, F. Casanova-Gomez, C. Sanchez-Contador, C. Santamariña, N. Aragonès, B.P. Gomez, J. Vioque, and M. Pollan. 2014. Calorie intake, olive oil consumption and mammographic density among Spanish women. International Journal of Cancer 134: 1916-1925."
  },
  {
    "href": "docs/tests/lectures-single.html#one-sample-t-test",
    "title": "Statistical tests",
    "section": "One sample t-test",
    "text": "Before considering the problem of comparing two groups, let us start looking at the weight of the male rats only:\n\nggplot(data=subset(data,gender==\"Male\")) + geom_point(aes(x=weight,y=0), colour=\"red\") + \n  ylab(NULL) + scale_y_continuous(breaks=NULL) + xlab(\"weight (g)\")\n\n\n\n\nLet x_1, x_2, x_n the weights of the n male rats. We will assume that the x_i’s are independent and normally distributed with mean \\mu and variance \\sigma^2:\n x_i \\iid {\\cal N}(\\mu \\ , \\ \\sigma^2) \n\nOne sided test\nWe want to test\nH_0: \\ ``\\mu \\leq \\mu_0\" \\quad \\text{versus} \\quad H_1: \\ ``\\mu > \\mu_0\" \nFunction t.test can be used for performing this test:\n\nx <- data[data$gender==\"Male\",\"weight\"]\nmu0 <- 500\nt.test(x, alternative=\"greater\", mu=mu0)\n\n\n    One Sample t-test\n\ndata:  x\nt = 1.2708, df = 77, p-value = 0.1038\nalternative hypothesis: true mean is greater than 500\n95 percent confidence interval:\n 498.0706      Inf\nsample estimates:\nmean of x \n 506.2218 \n\n\nLet us see what these outputs are and how they are computed.\nLet \\bar{x} = n^{-1}\\sum_{i=1}^n x_i be the empirical mean of the data.  \\bar{x} \\sim {\\cal N}(\\mu \\ , \\ \\frac{\\sigma^2}{n}) Then,  \\begin{aligned}\n\\frac{\\sqrt{n}(\\bar{x} - \\mu)}{\\sigma} \\ &   \\sim \\ {\\cal N}(0 \\ , \\ 1) \\\\ \n\\frac{\\sqrt{n}(\\bar{x} - \\mu)}{s} \\ &   \\sim  \\ t_{n-1} \n\\end{aligned} \nwhere s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2  is the empirical variance of the x_i’s.\nThe statistic used for the test should be a function of the data whose distribution under H_0 is known, and whose expected behavior under H_1 allows one to define a rejection region (or critical region) for the null hypothesis.\nHere, the test statistic is \nT_{\\rm stat} = \\frac{(\\bar{x} - \\mu_0)}{s/\\sqrt{n}}   which follows a t-distribution with n-1 degrees of freedom when \\mu=\\mu_0.\n\\bar{x} is expected to be less than or equal to \\mu_0 under the null hypothesis, and greater than \\mu_0 under the alternative hypothesis, Hence, T_{\\rm stat} is expected to be less than or equal to 0 under H_0 and greater than 0 under H_1. We then reject the null hypothesis H_0 if T_{\\rm stat} is greater than some threshold q.\nSuch decision rule may lead to two kinds of error:\n\nThe type I error is the incorrect rejection of null hypothesis when it is true,\nThe type II error is the failure to reject the null hypothesis when it is false.\n\nThe type I error rate or significance level is therefore the probability of rejecting the null hypothesis given that it is true.\nIn our case, for a given significance level \\alpha, we will reject H_0 if T_{\\rm stat} > qt_{1-\\alpha,n-1}, where qt_{1-\\alpha,n-1} is the quantile of order 1-\\alpha for a t-distribution with n-1 degrees of freedom.\nIndeed, by definition,\n \\begin{aligned}\n\\prob{\\text{reject } H_0 \\ | \\ H_0 \\ \\text{true}} &= {\\mathbb P}(T_{\\rm stat} > qt_{1-\\alpha,n-1} \\ | \\ \\mu \\leq \\mu_0) \\\\\n& \\leq {\\mathbb P}(T_{\\rm stat} > qt_{1-\\alpha,n-1} \\ | \\ \\mu = \\mu_0) \\\\\n& \\leq {\\mathbb P}(t_{n-1} > qt_{1-\\alpha,n-1}) \\\\\n& \\leq \\alpha\n\\end{aligned} \n\nalpha <- 0.05\nx.mean <- mean(x)\nx.sd <- sd(x)\nn <- length(x)\ndf <- n-1\nt.stat <- sqrt(n)*(x.mean-mu0)/x.sd\nc(t.stat,qt(1-alpha, df))\n\n[1] 1.270806 1.664885\n\n\nWe therefore don’t reject H_0 in our example since T_{\\rm stat} < qt_{1-\\alpha,n-1}.\nWe can equivalently compute the significance level for which the test becomes significant. This value is called the p-value: \\begin{aligned}\np_{\\rm value} & = \\max{\\mathbb P}_{H_0}(T_{\\rm stat} > T_{\\rm stat}^{\\rm obs}) \\\\\n& = {\\mathbb P}(T_{\\rm stat} > T_{\\rm stat}^{\\rm obs}  \\ | \\ \\mu=\\mu_0) \\\\\n&= 1 - \\prob{t_{n-1} \\leq T_{\\rm stat}^{\\rm obs}}\n\\end{aligned}\nNow, T_{\\rm stat} > qt_{1-\\alpha,n-1} under H_0 if and only if \\prob{t_{n-1} \\leq T_{\\rm stat}^{\\rm obs}} \\geq 1-\\alpha. Then, the test is significant at the level \\alpha if and only if p_{\\rm value}\\leq \\alpha.\n\np.value <- 1 - pt(t.stat,df) \nprint(p.value)\n\n[1] 0.1038119\n\n\n\n\n\nHere, we would reject H_0 for any significance level \\alpha \\geq 0.104.\nImportant: The fact that the test is not significant at the level \\alpha does not allow us to conclude that H_0 is true, i.e. that \\mu is less than or equal to 500. We can only say that the data does not allow us to conclude that \\mu>500.\nImagine now that we want to test if \\mu \\geq 515 for instance. The alternative here is H_1: \\ ``\\mu < 515.\n\nmu0 <- 515\nt.test(x, alternative=\"less\", mu=mu0)\n\n\n    One Sample t-test\n\ndata:  x\nt = -1.793, df = 77, p-value = 0.03845\nalternative hypothesis: true mean is less than 515\n95 percent confidence interval:\n    -Inf 514.373\nsample estimates:\nmean of x \n 506.2218 \n\n\nMore generally, we may want to test H_0: \\ ``\\mu \\geq \\mu_0\" \\quad \\text{versus} \\quad H_1: \\ ``\\mu < \\mu_0\"  We still use the statistic T_{\\rm stat} = \\sqrt{n}(\\bar{x}-\\mu_0)/s for this test, but the rejection region is now the area that lies to the left of the critical value qt_{\\alpha,n-1} since\n \\begin{aligned}\n\\prob{\\text{reject } H_0 \\ | \\ H_0 \\ \\text{true}} &= {\\mathbb P}(T_{\\rm stat} < qt_{\\alpha,n-1} \\ | \\ \\mu \\geq \\mu_0) \\\\\n& \\leq {\\mathbb P}(T_{\\rm stat} < qt_{\\alpha,n-1} \\ | \\ \\mu = \\mu_0) \\\\\n& \\leq \\alpha\n\\end{aligned} \n\nt.stat <- sqrt(n)*(x.mean-mu0)/x.sd\np.value <- pt(t.stat,df)\nc(t.stat, df, p.value)\n\n[1] -1.79295428 77.00000000  0.03845364\n\n\nHere, the p-value is less than \\alpha=0.05: we then reject the null hypothesis at the 5\\% level and conclude that \\mu < 515.\n\n\n\nTwo sided test\nA two sided test (or two tailed test) can be used to test if \\mu=500 for instance\n\nmu0 = 500\nt.test(x, alternative=\"two.sided\", mu=mu0)\n\n\n    One Sample t-test\n\ndata:  x\nt = 1.2708, df = 77, p-value = 0.2076\nalternative hypothesis: true mean is not equal to 500\n95 percent confidence interval:\n 496.4727 515.9709\nsample estimates:\nmean of x \n 506.2218 \n\n\nMore generally, we can test H_0: \\ ``\\mu = \\mu_0\" \\quad \\text{versus} \\quad H_1: \\ ``\\mu \\neq \\mu_0\"  The test also uses the statistic T_{\\rm stat} = \\sqrt{n}(\\bar{x}-\\mu_0)/s, but the rejection region has now two parts: we reject H_0 if |T_{\\rm stat}| > qt_{1-\\alpha/2}. Indeed,\n \\begin{aligned}\n\\prob{\\text{reject } H_0 \\ | \\ H_0 \\ \\text{true}} &= {\\mathbb P}(|T_{\\rm stat}| > qt_{1 -\\frac{\\alpha}{2},n-1} \\ | \\ \\mu = \\mu_0) \\\\\n& = {\\mathbb P}(T_{\\rm stat} < qt_{\\frac{\\alpha}{2},n-1} \\ | \\ \\mu = \\mu_0) +\n {\\mathbb P}(T_{\\rm stat} > qt_{1-\\frac{\\alpha}{2},n-1} \\ | \\ \\mu = \\mu_0)\\\\\n&= \\prob{t_{n-1} \\leq qt_{\\frac{\\alpha}{2},n-1}} +  \\prob{t_{n-1} \\geq qt_{1-\\frac{\\alpha}{2},n-1}} \\\\\n &= \\frac{\\alpha}{2} + \\frac{\\alpha}{2} \\\\\n& = \\alpha\n\\end{aligned} \nThe p-value of the test is now\n\\begin{aligned}\np_{\\rm value} & = {\\mathbb P}_{H_0}(|T_{\\rm stat}| > |T_{\\rm stat}^{\\rm obs}|) \\\\\n& = {\\mathbb P}_{H_0}(T_{\\rm stat} < -|T_{\\rm stat}^{\\rm obs}|)  + {\\mathbb P}_{H_0}(T_{\\rm stat} > |T_{\\rm stat}^{\\rm obs}|)\\\\\n&= \\prob{t_{n-1} \\leq -|T_{\\rm stat}^{\\rm obs}|} +  \\prob{t_{n-1} \\geq |T_{\\rm stat}^{\\rm obs}|} \\\\\n&= 2 \\,\\prob{t_{n-1} \\leq -|T_{\\rm stat}^{\\rm obs}|}\n\\end{aligned}\n\nt.stat <- sqrt(n)*(x.mean-mu0)/x.sd\np.value <- 2*pt(-abs(t.stat),df) \nc(t.stat, df, p.value)\n\n[1]  1.2708058 77.0000000  0.2076238\n\n\n\n\n\nHere, p_{\\rm value}= 0.208. Then, for any significance level less than 0.208, we cannot reject the hypothesis that \\mu = 500.\n\n\n\nConfidence interval for the mean\nWe have just seen that the data doesn’t allow us to reject the hypothesis that \\mu = 500. But we would come to the same conclusion with other values of \\mu_0. In particular, we will never reject the hypothesis that \\mu = \\bar{x}:\n\nt.test(x, mu=x.mean, conf.level=1-alpha)$p.value\n\n[1] 1\n\n\nFor a given significance level (\\alpha = 0.05 for instance), we will not reject the null hypothesis for values of \\mu_0 close enough to \\bar{x}.\n\npv.510 <- t.test(x, mu=510, conf.level=1-alpha)$p.value\npv.497 <- t.test(x, mu=497, conf.level=1-alpha)$p.value\nc(pv.510, pv.497)\n\n[1] 0.44265350 0.06340045\n\n\nOn the other hand, we will reject H_0 for values of \\mu_0 far enough from \\bar{x}:\n\npv.520 <- t.test(x, mu=520, conf.level=1-alpha)$p.value\npv.490 <- t.test(x, mu=490, conf.level=1-alpha)$p.value\nc(pv.520, pv.490)\n\n[1] 0.006204188 0.001406681\n\n\nThere exist two values of \\mu_0 for which the decision is borderline\n\npv1 <- t.test(x, mu=496.47, conf.level=1-alpha)$p.value\npv2 <- t.test(x, mu=515.97, conf.level=1-alpha)$p.value\nc(pv1,pv2)\n\n[1] 0.04993761 0.05001986\n\n\nIn fact, for a given \\alpha, these two values \\mu_{\\alpha,{\\rm lower}} and \\mu_{\\alpha,{\\rm upper}} define a confidence interval for \\mu: We are ``confident’’ at the level 1-\\alpha that any value between \\mu_{\\alpha,{\\rm lower}} and \\mu_{\\alpha,{\\rm upper}} is a possible value for \\mu.\n\nmu <- seq(490,520,by=0.25)\nt.stat <- (x.mean-mu)/x.sd*sqrt(n)\npval <- pmin(pt(-t.stat,df) + (1- pt(t.stat,df)),pt(t.stat,df) + (1- pt(-t.stat,df)))\ndd <- data.frame(mu=mu, p.value=pval)\nCI <- x.mean + x.sd/sqrt(n)*qt(c(alpha/2,1-alpha/2), df)\nggplot(data=dd) + geom_line(aes(x=mu,y=p.value)) + \n  geom_vline(xintercept=x.mean,colour=\"red\", linetype=2)+\n  geom_hline(yintercept=alpha,colour=\"green\", linetype=2)+\n  geom_vline(xintercept=CI,colour=\"red\") +\n  scale_x_continuous(breaks=round(c(490,500,510,520,CI,x.mean),2)) \n\n\n\n\nBy construction,\n\\begin{aligned}\n1-\\alpha &=  \\prob{ qt_{\\frac{\\alpha}{2},n-1} < \\frac{\\bar{x}-\\mu}{s/\\sqrt{n}} < qt_{1-\\frac{\\alpha}{2},n-1} } \\\\\n&= \\prob{ \\bar{x} +\\frac{s}{\\sqrt{n}}qt_{\\frac{\\alpha}{2},n-1} < \\mu < \\bar{x} +\\frac{s}{\\sqrt{n}}qt_{1-\\frac{\\alpha}{2},n-1} } \n\\end{aligned}\nThe confidence interval of level 1-\\alpha for \\mu is therefore the interval {\\rm CI}_{1-\\alpha} = [\\bar{x} +\\frac{s}{\\sqrt{n}}qt_{\\frac{\\alpha}{2},n-1} \\ \\ , \\ \\ \n\\bar{x} +\\frac{s}{\\sqrt{n}}qt_{1-\\frac{\\alpha}{2},n-1}] \n\n(CI <- x.mean + x.sd/sqrt(n)*qt(c(alpha/2,1-alpha/2), df))\n\n[1] 496.4727 515.9709\n\n\nRemark 1: The fact that \\prob{ \\mu \\in {\\rm CI}_{1-\\alpha}} = 1- \\alpha does not mean that \\mu is a random variable! It is the bounds of the confidence interval that are random because they are function of the data.\nA confidence interval of level 1-\\alpha should be interpreted like this: imagine that we repeat the same experiment many times, with the same experimental conditions, and that we build a confidence interval for \\mu for each of these replicate. Then, the true mean \\mu will lie in the confidence interval (1-\\alpha)100\\% of the times.\nLet us check this property with a Monte Carlo simulation.\n\nL <- 100000\nn <- 100\nmu <- 500\nsd <- 40\nR <- vector(length=L)\nfor (l in (1:L)) {\n  x <- rnorm(n,mu,sd)\n  ci.l <- mean(x) + sd(x)/sqrt(n)*qt(c(alpha/2, 1-alpha/2),n-1)\n  R[l] <- (mu > ci.l[1]  && mu < ci.l[2])\n}\nmean(R)\n\n[1] 0.95065\n\n\nRemark 2:\nThe decision rule to reject or not the null hypothesis can be derived from the confidence interval. Indeed, the confidence interval plays the role of an acceptance region: we reject H_0 if \\mu_0 does not belong to {\\rm CI}_{1-\\alpha}.\nIn the case of a one sided test, the output of t.test called confidence interval is indeed an acceptance region for \\mu, but not a ``confidence interval’’ (we cannot seriouly consider that \\mu can take any value above 500 for instance )\n\nrbind(\nc(x.mean + x.sd/sqrt(n)*qt(alpha,df) , Inf),\nc(-Inf, x.mean + x.sd/sqrt(n)*qt(1-alpha,df)))\n\n         [,1]     [,2]\n[1,] 499.0229      Inf\n[2,]     -Inf 513.4207"
  },
  {
    "href": "docs/tests/lectures-single.html#two-samples-t-test",
    "title": "Statistical tests",
    "section": "Two samples t-test",
    "text": "What should we test?\nLet us now compare the weights of the male and female rats. ::: {.cell}\ny <- data[data$gender==\"Female\" ,\"weight\"]\n\ndmean <- data.frame(x=c(mean(x),mean(y)),gender=c(\"Male\",\"Female\"))\n\nggplot(data=subset(data,regime==\"Control\")) + geom_point(aes(x=weight,y=0,colour=gender)) + \n  geom_point(data=dmean, aes(x,y=0,colour=gender), size=4) + \n  ylab(NULL) + scale_y_continuous(breaks=NULL) + xlab(\"weight (g)\")\n\n\n\n:::\nLooking at the data is more than enough for concluding that the mean weight of the males is (much) larger than the mean weight of the females Computing a p-value here is of little interest \n\nt.test(x, y)\n\n\n    Welch Two Sample t-test\n\ndata:  x and y\nt = 46.45, df = 163.44, p-value < 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 211.5862 230.3738\nsample estimates:\nmean of x mean of y \n 503.7825  282.8025 \n\n\nLet us see now what happens if we compare the control and GMO groups for the male rats. ::: {.cell}\nx <- data[data$gender==\"Male\" & data$regime==\"Control\",\"weight\"]\ny <- data[data$gender==\"Male\" & data$regime==\"GMO\",\"weight\"]\n\ndmean <- data.frame(x=c(mean(x),mean(y)),regime=c(\"Control\",\"GMO\"))\nggplot(data=data[data$gender==\"Male\",]) +  geom_point(aes(x=weight,y=as.numeric(regime),colour=regime)) +\n  geom_point(data=dmean, aes(x,y=as.numeric(regime),colour=regime), size=4) + \n  ylab(NULL) + scale_y_continuous(breaks=NULL, limits=c(-6,9)) + xlab(\"weight (g)\")\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n:::\nWe observe a difference between the two empirical means (the mean weight after 14 weeks is greater in the control group), but we cannot say how significant this difference is by simply looking at the data. Performing a statistical test is now necessary.\nLet x_{1}, x_{2}, \\ldots, x_{n_x} be the weights of the n_x male rats of the control group and y_{1}, y_{2}, \\ldots, y_{n_x} the weights of the n_y male rats of the GMO group. We will assume normal distributions for both (x_{i}) and (y_{i}):\n x_{i} \\iid {\\cal N}(\\mu_x \\ , \\ \\sigma^2_x) \\quad ; \\quad y_{i} \\iid {\\cal N}(\\mu_y \\ , \\ \\sigma^2_y)\nWe want to test\nH_0: \\ ``\\mu_x = \\mu_y\" \\quad \\text{versus} \\quad H_1: \\ ``\\mu_x \\neq \\mu_y\" \n\n\n\nAssuming equal variances\nWe can use the function t.test assuming first equal variances (\\sigma^2_x=\\sigma_y^2) ::: {.cell}\nalpha <- 0.05\nt.test(x, y, conf.level=1-alpha, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = 1.5426, df = 76, p-value = 0.1271\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.358031 34.301621\nsample estimates:\nmean of x mean of y \n 513.7077  498.7359 \n\n::: The test statistic is T_{\\rm stat} = \\frac{\\bar{x} - \\bar{y}}{s_p \\sqrt{\\frac{1}{n_x}+\\frac{1}{n_y}}}   where s_p^2 is the pooled variance:\ns_p^2 = \\frac{1}{n_x+n_y-2} \\left(\\sum_{i=1}^{n_x} (x_{i}-\\bar{x})^2 + \\sum_{i=1}^{n_y} (y_{i}-\\bar{y})^2 \\right)  \nUnder the null hypothesis, T_{\\rm stat} follows a t-distribution with n_x+n_y-2 degree of freedom. The p-value is therefore\n\\begin{aligned}\np_{\\rm value} & = {\\mathbb P}_{H_0}(|T_{\\rm stat}| > |T_{\\rm stat}^{\\rm obs}|) \\\\\n&= \\prob{t_{n_x+n_y-2} \\leq -T_{\\rm stat}^{\\rm obs}} + 1 - \\prob{t_{n_x+n_y-2} \\leq T_{\\rm stat}^{\\rm obs}}\n\\end{aligned}\n\nnx <- length(x)\nny <- length(y)\nx.mean <- mean(x)\ny.mean <- mean(y)\nx.sc <- sum((x-x.mean)^2)\ny.sc <- sum((y-y.mean)^2)\nxy.sd <- sqrt((x.sc+y.sc)/(nx+ny-2))\nt.stat <- (x.mean-y.mean)/xy.sd/sqrt(1/nx+1/ny)\ndf <- nx + ny -2\np.value <- pt(-t.stat,df) + (1- pt(t.stat,df))\nc(t.stat, df, p.value)\n\n[1]  1.5426375 76.0000000  0.1270726\n\n\nThe confidence interval for the mean difference \\mu_x-\\mu_y is computed as {\\rm CI}_{1-\\alpha} = [\\bar{x} - \\bar{y} +s_p \\sqrt{\\frac{1}{n_x}+\\frac{1}{n_y}}qt_{\\frac{\\alpha}{2},n_x+n_y-2} \\ \\ , \\ \\ \n\\bar{x} - \\bar{y} +s_p \\sqrt{\\frac{1}{n_x}+\\frac{1}{n_y}}qt_{1-\\frac{\\alpha}{2},n_x+n_y-2} ] \n\nx.mean-y.mean  + xy.sd*sqrt(1/nx+1/ny)*qt(c(alpha/2,1-alpha/2),df)\n\n[1] -4.358031 34.301621\n\n\n\n\n\nAssuming different variances\nAssuming equal variances for the two groups may be disputable. ::: {.cell}\naggregate(data$weight ~ data$regime, FUN= \"sd\" )\n\n  data$regime data$weight\n1     Control    123.0689\n2         GMO    111.8559\n\n:::\nWe can then use the t.test function with different variances (which is the default) ::: {.cell}\nt.test(x, y, conf.level=1-alpha)\n\n\n    Welch Two Sample t-test\n\ndata:  x and y\nt = 1.5426, df = 75.976, p-value = 0.1271\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.358129 34.301719\nsample estimates:\nmean of x mean of y \n 513.7077  498.7359 \n\n:::\n\n\n\nThe Welch (or Satterthwaite) approximation to the degrees of freedom is used instead of n_x+n_y-2= 76:\n\\df_W = \\frac{(c_x + c_y)^2}{{c_x^2}/{(n_x-1)} + {c_y^2}/{(n_y-1)}} where c_x = \\sum (x_{i}-\\bar{x})^2/(n_x(n_x-1)) and c_y = \\sum (y_{i}-\\bar{y})^2/(n_y(n_y-1)).\nFurthermore, unlike in Student’s t-test with equal variances, the denominator is not based on a pooled variance estimate:\nT_{\\rm stat} = \\frac{\\bar{x} - \\bar{y}}{ \\sqrt{{s_x^2}/{n_x}+{s_y^2}/{n_y}}}   where s_x^2 and s_y^2 are the empirical variances of (x_i) and (y_i):  s_x^2 = \\frac{1}{n_x-1}\\sum_{i=1}^{n_x} (x_{i}-\\bar{x})^2  \\quad ; \\quad\ns_y^2 = \\frac{1}{n_y-1}\\sum_{i=1}^{n_y} (y_{i}-\\bar{y})^2\n\nsbar.xy <- sqrt(var(x)/nx+var(y)/ny)\nt.stat <- (x.mean-y.mean)/sbar.xy\ncx <- x.sc/(nx-1)/nx\ncy <- y.sc/(ny-1)/ny\ndfw <- (cx + cy)^2 / (cx^2/(nx-1) + cy^2/(ny-1))\np.value <- pt(-t.stat,dfw) + (1- pt(t.stat,dfw))\nc(t.stat, dfw, p.value)\n\n[1]  1.5426375 75.9760868  0.1270739\n\n\nThe confidence interval for \\mu_x-\\mu_y is now computed as {\\rm CI}_{1-\\alpha} = [\\bar{x} - \\bar{y} +\\sqrt{\\frac{s_x^2}{n_x}+\\frac{s_y^2}{n_y}} \\ qt_{\\frac{\\alpha}{2},\\df_W} \\ \\ , \\ \\ \n\\bar{x} - \\bar{y} +\\sqrt{\\frac{s_x^2}{n_x}+\\frac{s_y^2}{n_y}} \\ qt_{1-\\frac{\\alpha}{2},\\df_W} ] \n\nx.mean-y.mean  + sbar.xy*qt(c(alpha/2,1-alpha/2),dfw)\n\n[1] -4.358129 34.301719"
  },
  {
    "href": "docs/tests/lectures-single.html#power-of-a-t-test",
    "title": "Statistical tests",
    "section": "Power of a t-test",
    "text": "Until now, we have demonstrated that the experimental data does not highlight any significant difference in weight between the control group and the GMO group.\nOf course, that does not mean that there is no difference between the two groups. Indeed, absence of evidence is not evidence of absence. In fact, no experimental study would be able to demonstrate the absence of effect of the diet on the weight.\nNow, the appropriate question is rather to evaluate what the experimental study can detect. If feeding a population of rats with GMOs has a signicant biological effect on the weight, can we ensure with a reasonable level of confidence that our statistical test will reject the null hypothesis and conclude that there is indeed a difference in weight between the two groups?\nA power analysis allows us to determine the sample size required to detect an effect of a given size with a given degree of confidence. Conversely, it allows us to determine the probability of detecting an effect of a given size with a given level of confidence, under sample size constraints.\nFor a given \\delta \\in {\\mathbb R}, let \\beta(\\delta) be the type II error rate, i.e. the probability to fail rejecting H_0 when \\mu_x-\\mu_y = \\delta, with \\delta\\neq 0.\nThe power of the test is the probability to reject the null hypothesis when it is false. It is also a function of \\delta =\\mu_x-\\mu_y defined as\n \\begin{aligned}\n\\eta(\\delta) &= 1 - \\beta(\\delta) \\\\\n&= \\prob{\\text{reject } H_0 \\ | \\ \\mu_x-\\mu_y=\\delta } \n\\end{aligned} \nRemember that, for a two sided test, we reject the null hypothesis when |T_{\\rm stat}| > qt_{1-\\alpha/2, \\df}, where \\df is the appropriate degree of freedom.\nOn the other hand, {(\\bar{x} - \\bar{y} - \\delta)}/{s_{xy}}, where s_{xy} = \\sqrt{{s_x^2}/{n_x}+{s_y^2}/{n_y}}, follows a t-distribution with \\df degrees of freedom. Thus,\n \\begin{aligned}\n\\eta(\\delta) &= 1 - {\\mathbb P}(qt_{\\frac{\\alpha}{2},\\df} < T_{\\rm stat} < qt_{1 -\\frac{\\alpha}{2},\\df} \\ | \\ \\mu_x-\\mu_y=\\delta) \\\\\n& = 1- {\\mathbb P}(qt_{\\frac{\\alpha}{2},\\df} < \\frac{\\bar{x} - \\bar{y}}{s_{xy}} < qt_{1-\\frac{\\alpha}{2},\\df} \\ | \\ \\mu_x-\\mu_y=\\delta) \\\\\n&= 1- {\\mathbb P}(qt_{\\frac{\\alpha}{2},\\df} - \\frac{\\delta}{s_{xy}} < \\frac{\\bar{x} - \\bar{y} - \\delta}{s_{xy}} < qt_{1-\\frac{\\alpha}{2},\\df} - \\frac{\\delta}{s_{xy}} \\ | \\ \\mu_x-\\mu_y=\\delta) \\\\\n&= 1 - Ft_{\\df}(qt_{1-\\frac{\\alpha}{2},\\df} - \\frac{\\delta}{s_{xy}}) + Ft_{\\df}(qt_{\\frac{\\alpha}{2},\\df} - \\frac{\\delta}{s_{xy}})\n\\end{aligned} \nAs an example, let us compute the probability to detect a difference in weight of 10g with two groups of 80 rats each and assuming that the standard deviation is 30g in each group.\n\nalpha=0.05\nnx.new <- ny.new <- 80\ndelta.mu <- 10\nx.sd <- 30\ndf <- nx.new+ny.new-2\ndt <- delta.mu/x.sd/sqrt(1/nx.new+1/ny.new)\n1-pt(qt(1-alpha/2,df)-dt,df) + pt(qt(alpha/2,df)-dt,df) \n\n[1] 0.5528906\n\n\nThe function pwr.t.test allows to compute this power:\n\nlibrary(pwr)\npwr.t.test(n=nx.new, d=delta.mu/x.sd, type=\"two.sample\", alternative=\"two.sided\", sig.level=alpha)\n\n\n     Two-sample t test power calculation \n\n              n = 80\n              d = 0.3333333\n      sig.level = 0.05\n          power = 0.5538758\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nLet us perform a Monte Carlo simulation, to check this result and better understand what it means. Imagine that the ``true’’ difference in weight is \\delta=10g. Then, if could repeat the same experiment a (very) large number of times, we would reject the null hypothesis in 55\\% of cases.\n\nL <- 100000\nmux <- 500\nmuy <- mux + delta.mu\nRt <- vector(length=L)\nfor (l in (1:L)) {\n  x.sim <- rnorm(nx.new,mux,x.sd)\n  y.sim <- rnorm(ny.new,muy,x.sd)\n  Rt[l] <- t.test(x.sim, y.sim, alternative=\"two.sided\")$p.value < alpha\n}\nmean(Rt)\n\n[1] 0.55335\n\n\nWe may consider this probability as too small. If our objective is a power of 80% at least, with the same significance level, we need to increase the sample size.\n\npwr.t.test(power=0.8, d=delta.mu/x.sd, sig.level=alpha) \n\n\n     Two-sample t test power calculation \n\n              n = 142.2462\n              d = 0.3333333\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n\n\nIndeed, we see that n\\geq 143 animals per group are required in order to reach a power of 80%.\n\nnx.new <- ny.new <- ceiling(pwr.t.test(power=0.8, d=delta.mu/x.sd, sig.level=alpha)$n)\ndf <- nx.new+ny.new-2\ndt <- delta.mu/x.sd/sqrt(1/nx.new+1/ny.new)\n1-pt(qt(1-alpha/2,df)-dt,df) + pt(qt(alpha/2,df)-dt,df)\n\n[1] 0.8020466\n\n\nAn alternative for increasing the power consists in increasing the type I error rate\n\npwr.t.test(power=0.8, d=delta.mu/x.sd, n=80, sig.level=NULL) \n\n\n     Two-sample t test power calculation \n\n              n = 80\n              d = 0.3333333\n      sig.level = 0.2067337\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nIf we accept a significance level of about 20%, then we will be less demanding for rejecting H_0: we will reject the null hypothesis when |T_{\\rm stat}|>qt_{0.9,158}= 1.29, instead of |T_{\\rm stat}|>qt_{0.975,158}= 1.98. This strategy will therefore increase the power, but also the type I error rate."
  },
  {
    "href": "getting-started.html",
    "title": "Setup instructions",
    "section": "",
    "text": "R and RStudio are separate downloads and installations\n\nR is the underlying statistical computing environment\nRStudio is a graphical integrated development environment (IDE)\n\n\nInstalling R\nGo to the CRAN webpage, select your OS and follow the instructions.\n\n\nInstalling RStudio Desktop\nGo to the download page. Select, download and install the file corresponding to your OS.\n\n\nInstalling R packages\nLaunch Rstudio and execute the following commands in the console (at least these R packages will be needed during MAP566)\n\ninstall.packages(\"tidyverse\")\n\n\nOn Windows\n\nYou may need Rtools (dedicated page) and git (dedicated page)\n\nOn MacOS\n\nYou may need XCode: visit the dedicated page, download the Mandatory tools and install them on your computer\n\nOn Linux\n\nIf installation of a package fails in Rstudio, just READ THE MESSAGES: you may be asked to install some missing system libraries with, e.g.,\n\nsudo apt-get install lib-missing\n\n\n\n\n\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) {\n  const icon = \"\";\n  const anchorJS = new window.AnchorJS();\n  anchorJS.options = {\n    placement: 'right',\n    icon: icon\n  };\n  anchorJS.add('.anchored');\n  const clipboard = new window.ClipboardJS('.code-copy-button', {\n    target: function(trigger) {\n      return trigger.previousElementSibling;\n    }\n  });\n  clipboard.on('success', function(e) {\n    // button target\n    const button = e.trigger;\n    // don't keep focus\n    button.blur();\n    // flash \"checked\"\n    button.classList.add('code-copy-button-checked');\n    setTimeout(function() {\n      button.classList.remove('code-copy-button-checked');\n    }, 1000);\n    // clear code selection\n    e.clearSelection();\n  });\n  function tippyHover(el, contentFn) {\n    window.tippy(el, {\n      allowHTML: true,\n      content: contentFn,\n      maxWidth: 500,\n      delay: 100,\n      interactive: true,\n      interactiveBorder: 10,\n      theme: 'quarto',\n      placement: 'bottom-start'\n    }); \n  }\n  const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n  for (var i=0; i<noterefs.length; i++) {\n    const ref = noterefs[i];\n    tippyHover(ref, function() {\n      const id = new URL(ref.getAttribute('href')).hash.replace(/^#/, \"\");\n      const note = window.document.getElementById(id);\n      return note.innerHTML;\n    });\n  }\n  var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n  for (var i=0; i<bibliorefs.length; i++) {\n    const ref = bibliorefs[i];\n    const cites = ref.parentNode.getAttribute('data-cites').split(' ');\n    tippyHover(ref, function() {\n      var popup = window.document.createElement('div');\n      cites.forEach(function(cite) {\n        var citeDiv = window.document.createElement('div');\n        citeDiv.classList.add('hanging-indent');\n        citeDiv.classList.add('csl-entry');\n        var biblioDiv = window.document.getElementById('ref-' + cite);\n        if (biblioDiv) {\n          citeDiv.innerHTML = biblioDiv.innerHTML;\n        }\n        popup.appendChild(citeDiv);\n      });\n      return popup.innerHTML;\n    });\n  }\n});"
  }
]